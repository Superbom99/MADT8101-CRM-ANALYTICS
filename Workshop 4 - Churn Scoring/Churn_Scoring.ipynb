{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Superbom99/MADT8101-SEMINAR-IN-ADVANCED-ANALYTICS/blob/main/Churn_Scoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Churn Scoring"
      ],
      "metadata": {
        "id": "p0vcvsfU1poH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Introduction**\n",
        "\n",
        "Customer churn is a major problem for businesses of all sizes. It can lead to lost revenue, decreased customer satisfaction, and increased marketing costs. By predicting which customers are most likely to churn, businesses can take steps to prevent them from leaving.\n",
        "\n",
        "Churn scoring is a machine learning technique that can be used to predict customer churn. It involves creating a model that assigns a score to each customer, based on their historical data and other factors. The higher the score, the more likely the customer is to churn.\n",
        "\n",
        "In this blog post, we will walk through the steps involved in churn scoring using Python. We will use a public dataset of customer churn data from a telecommunications company."
      ],
      "metadata": {
        "id": "udb3pLZx2sRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Step 1: Import the libraries**\n",
        "\n",
        "The first step is to import the libraries that we will need. These include:\n",
        "\n",
        "pandas: for data manipulation\n",
        "numpy: for mathematical operations\n",
        "scikit-learn: for machine learning"
      ],
      "metadata": {
        "id": "HxipYZKr12C5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "P6Dhh8b41poJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Step 2: Load the dataset**\n",
        "\n",
        "The next step is to load the dataset. We can do this using the `read_csv()` function from the pandas library."
      ],
      "metadata": {
        "id": "NfSMgwAm1poK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('churn_data.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "FcFQSit21poK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Step 3: Explore the dataset**\n",
        "\n",
        "Before we start building our model, it is important to explore the dataset. This will help us to understand the data and identify any potential problems.\n",
        "\n",
        "We can explore the dataset using the following commands:\n",
        "\n",
        "* `head()`: to display the first few rows of the dataset\n",
        "* `describe()`: to get a summary of the statistical distribution of the data\n",
        "* `info()`: to get information about the data types and missing values"
      ],
      "metadata": {
        "id": "NpFIWbUF1poK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()\n",
        "\n",
        "dataset.describe()\n",
        "\n",
        "dataset.info()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Hy_LTY381poK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4: Select the features**\n",
        "\n",
        "The next step is to select the features that we will use to build our model. We need to select features that are predictive of customer churn.\n",
        "\n",
        "We can select the features using the following steps:\n",
        "\n",
        "1. Identify the features that are related to customer churn.\n",
        "2. Remove features that are not relevant or that are too noisy.\n",
        "3. Normalize the features so that they have a similar scale."
      ],
      "metadata": {
        "id": "YMwVq77N1poK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the features that are related to customer churn.\n",
        "churn_related_features = [\n",
        "    'tenure',\n",
        "    'monthly_charges',\n",
        "    'contract_type',\n",
        "    'payment_method',\n",
        "    'number_of_calls',\n",
        "    'number_of_texts',\n",
        "    'number_of_data_usage'\n",
        "]\n",
        "\n",
        "# Remove features that are not relevant or that are too noisy.\n",
        "not_relevant_features = ['customer_id', 'gender']\n",
        "noisy_features = ['customer_name']\n",
        "\n",
        "# Normalize the features.\n",
        "for feature in churn_related_features:\n",
        "    dataset[feature] = (dataset[feature] - dataset[feature].mean()) / dataset[feature].std()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "7uMsyl_E1poK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Step 5: Build the model**\n",
        "\n",
        "Now that we have selected the features, we can build the model. We will use a random forest classifier for this task.\n",
        "\n",
        "A random forest classifier is an ensemble learning algorithm that builds multiple decision trees and then combines their predictions to make a final decision."
      ],
      "metadata": {
        "id": "go45eYc81poL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random forest classifier.\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Fit the model to the training data.\n",
        "model.fit(X_train, y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "552as-vu1poL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Step 6: Evaluate the model**\n",
        "\n",
        "Once the model is built, we need to evaluate its performance. We can do this using the following metrics:\n",
        "\n",
        "* Accuracy: the percentage of predictions that are correct\n",
        "* Precision: the percentage of positive predictions that are actually positive\n",
        "* Recall: the percentage of actual positives that are predicted as positive"
      ],
      "metadata": {
        "id": "qEktSpSF1poL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data.\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "precision = np.mean(y_pred[y_test == 1])\n",
        "recall = np.mean(y_test[y_pred == 1])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "qWgiging1poL"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
